{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9731b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "195dcbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class4    class2  class2_label  class4_label\n",
      "232  nonevent  nonevent             0             0\n",
      "283        II     event             1             1\n",
      "230  nonevent  nonevent             0             0\n",
      "113        Ib     event             1             2\n",
      "82   nonevent  nonevent             0             0\n",
      "405  nonevent  nonevent             0             0\n",
      "340  nonevent  nonevent             0             0\n",
      "196  nonevent  nonevent             0             0\n",
      "57         Ib     event             1             2\n",
      "131        Ia     event             1             3\n",
      "\n",
      "train_df: (450, 107)\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "# æ ¹æ®class4ç”Ÿæˆclass2\n",
    "# nonevent ä¸º 0ï¼Œevent ä¸º 1\n",
    "# nonevent ä¸º 0ï¼ŒII ä¸º 1ï¼ŒIb ä¸º 2ï¼ŒIa ä¸º 3\n",
    "train_df['class2'] = np.where(train_df['class4'] == 'nonevent', 'nonevent', 'event')\n",
    "train_df['class2_label'] = (train_df['class2'] == 'event').astype(int)\n",
    "train_df['class4_label'] = train_df['class4'].map({'nonevent': 0, 'II': 1, 'Ib': 2, 'Ia': 3})\n",
    "target_labels = ['class2','class4','class2_label','class4_label']\n",
    "\n",
    "print(train_df[['class4', 'class2', 'class2_label','class4_label']].sample(10))\n",
    "\n",
    "print(f\"\\ntrain_df: {train_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b91e5dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_df preview:\n",
      "   id        date  partlybad  CO2168.mean  CO2168.std  CO2336.mean  \\\n",
      "0   0  2000-03-21      False   372.396757    0.752494   372.279392   \n",
      "1   1  2000-03-23      False   372.889867    0.410639   372.769205   \n",
      "2   2  2000-04-07      False   373.869464    0.655604   373.788580   \n",
      "3   3  2000-04-09      False   376.006588    1.109789   375.888889   \n",
      "4   4  2000-04-14      False   374.068239    1.257096   374.042330   \n",
      "\n",
      "   CO2336.std  CO242.mean  CO242.std  CO2504.mean  ...  T672.mean  T672.std  \\\n",
      "0    0.716926  372.876081   0.817532   372.207838  ...   2.729459  2.041327   \n",
      "1    0.380586  373.387815   0.478567   372.714967  ...  -1.259602  1.888414   \n",
      "2    0.649312  374.356310   0.629567   373.737083  ...   2.079822  1.610976   \n",
      "3    1.052157  376.779883   1.403241   375.806257  ...   3.499965  2.831278   \n",
      "4    1.214805  374.725480   1.374858   374.048523  ...   1.421619  0.934736   \n",
      "\n",
      "   T84.mean   T84.std  UV_A.mean   UV_A.std  UV_B.mean  UV_B.std   CS.mean  \\\n",
      "0  3.615784  2.283825   6.237543   4.372063   0.115203  0.104295  0.000510   \n",
      "1 -0.323360  1.979027  11.626868   7.208083   0.301720  0.229672  0.000706   \n",
      "2  3.181058  1.929516  16.688892  10.504951   0.561251  0.451130  0.000851   \n",
      "3  4.677937  3.161601  17.456796  10.967471   0.716453  0.572409  0.002083   \n",
      "4  2.009219  0.929537   4.279844   2.425409   0.146308  0.106017  0.002650   \n",
      "\n",
      "     CS.std  \n",
      "0  0.000123  \n",
      "1  0.000250  \n",
      "2  0.000244  \n",
      "3  0.000203  \n",
      "4  0.000891  \n",
      "\n",
      "[5 rows x 103 columns]\n",
      "train_y_df preview:\n",
      "     class2    class4  class2_label  class4_label\n",
      "0     event        II             1             1\n",
      "1  nonevent  nonevent             0             0\n",
      "2     event        Ia             1             3\n",
      "3     event        Ib             1             2\n",
      "4  nonevent  nonevent             0             0\n"
     ]
    }
   ],
   "source": [
    "train_X_df = train_df.drop(columns=target_labels)\n",
    "train_y_df = train_df[target_labels]\n",
    "\n",
    "print(\"train_X_df preview:\")\n",
    "print(train_X_df.head())\n",
    "\n",
    "print(\"train_y_df preview:\")\n",
    "print(train_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0505b6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_df preview:\n",
      "   CO2168.mean  CO2168.std  CO2336.mean  CO2336.std  CO242.mean  CO242.std  \\\n",
      "0   372.396757    0.752494   372.279392    0.716926  372.876081   0.817532   \n",
      "1   372.889867    0.410639   372.769205    0.380586  373.387815   0.478567   \n",
      "2   373.869464    0.655604   373.788580    0.649312  374.356310   0.629567   \n",
      "3   376.006588    1.109789   375.888889    1.052157  376.779883   1.403241   \n",
      "4   374.068239    1.257096   374.042330    1.214805  374.725480   1.374858   \n",
      "\n",
      "   CO2504.mean  CO2504.std   Glob.mean    Glob.std  ...   T84.std  UV_A.mean  \\\n",
      "0   372.207838    0.681111  127.050319  109.742153  ...  2.283825   6.237543   \n",
      "1   372.714967    0.360547  215.997636  157.220231  ...  1.979027  11.626868   \n",
      "2   373.737083    0.633824  348.039584  209.405812  ...  1.929516  16.688892   \n",
      "3   375.806257    0.960352  365.411700  215.367254  ...  3.161601  17.456796   \n",
      "4   374.048523    1.184708   58.798347   34.158414  ...  0.929537   4.279844   \n",
      "\n",
      "    UV_A.std  UV_B.mean  UV_B.std   CS.mean    CS.std  year  month  day  \n",
      "0   4.372063   0.115203  0.104295  0.000510  0.000123  2000      3   21  \n",
      "1   7.208083   0.301720  0.229672  0.000706  0.000250  2000      3   23  \n",
      "2  10.504951   0.561251  0.451130  0.000851  0.000244  2000      4    7  \n",
      "3  10.967471   0.716453  0.572409  0.002083  0.000203  2000      4    9  \n",
      "4   2.425409   0.146308  0.106017  0.002650  0.000891  2000      4   14  \n",
      "\n",
      "[5 rows x 103 columns]\n"
     ]
    }
   ],
   "source": [
    "# data clean\n",
    "# drop id\n",
    "train_X_df = train_X_df.drop(columns=['id'])\n",
    "# All of partlybad is False \n",
    "train_X_df = train_X_df.drop(columns=['partlybad'])\n",
    "# drop date and split date to year, month, day\n",
    "train_X_df['year'] = train_X_df['date'].str[:4].astype(int)\n",
    "train_X_df['month'] = train_X_df['date'].str[5:7].astype(int)\n",
    "train_X_df['day'] = train_X_df['date'].str[8:].astype(int)\n",
    "train_X_df = train_X_df.drop(columns=['date'])\n",
    "\n",
    "# train_X_df['PTG.mean'] = train_X_df['PTG.mean'].fillna(train_X_df['PTG.mean'].mean())\n",
    "# train_X_df['PTG.std'] = train_X_df['PTG.std'].fillna(train_X_df['PTG.std'].mean())\n",
    "\n",
    "print(\"train_X_df preview:\")\n",
    "print(train_X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "90130743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check NANæˆ–0\n",
    "# def check_quality(df):    \n",
    "#     # NAN\n",
    "#     missing_count = df.isnull().sum()\n",
    "#     missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "#     # 0\n",
    "#     numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "#     zero_count = (df[numeric_cols] == 0).sum()\n",
    "#     zero_percent = ((df[numeric_cols] == 0).sum() / len(df)) * 100\n",
    "    \n",
    "#     report = pd.DataFrame({\n",
    "#         'Missing_Count': missing_count,\n",
    "#         'Missing_%': missing_percent,\n",
    "#         'Zero_Count': zero_count,\n",
    "#         'Zero_%': zero_percent\n",
    "#     })\n",
    "    \n",
    "#     problematic_cols = report[(report['Missing_%'] > 0) | (report['Zero_%'] > 0)].sort_values('Missing_%', ascending=False)\n",
    "    \n",
    "    \n",
    "#     print(f\"å‘ç° {len(problematic_cols)} ä¸ªæœ‰æ½œåœ¨é—®é¢˜çš„åˆ—ï¼š\")\n",
    "#     print(problematic_cols.head(20))\n",
    "        \n",
    "#     return problematic_cols\n",
    "\n",
    "# train_report = check_quality(train_X_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2939e99",
   "metadata": {},
   "source": [
    "å‘ç°äº†PTGçš„æ•°æ®æœ‰å¼‚å¸¸ï¼ŒåæœŸè®­ç»ƒçš„æ—¶å€™å¯ä»¥æœ‰é€‰æ‹©çš„å»æ‰å¼‚å¸¸å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "750b7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO é™ç»´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e260af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_df: (360, 103)\n",
      "val_X_df: (90, 103)\n",
      "train_y_df: (360,)\n",
      "val_y_df: (90,)\n"
     ]
    }
   ],
   "source": [
    "# 8:2\n",
    "train_X_df, val_X_df, train_y_df, val_y_df = train_test_split(\n",
    "    train_X_df, train_y_df['class2_label'], test_size=0.2, random_state=42\n",
    ")\n",
    "# print shape\n",
    "print(f\"train_X_df: {train_X_df.shape}\")\n",
    "print(f\"val_X_df: {val_X_df.shape}\")\n",
    "print(f\"train_y_df: {train_y_df.shape}\")\n",
    "print(f\"val_y_df: {val_y_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d6f7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred_class, y_pred_proba):\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_true, y_pred_class)\n",
    "    \n",
    "    # Perplexity\n",
    "    prob_correct = np.where(y_true == 1, y_pred_proba, 1 - y_pred_proba)\n",
    "    prob_correct = np.clip(prob_correct, 1e-15, 1 - 1e-15) \n",
    "    perplexity = np.exp2(-np.mean(np.log2(prob_correct)))\n",
    "\n",
    "    return acc, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "69dbb4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. é€»è¾‘å›å½’ ---\n",
      "C Value    | Accuracy   | Perplexity\n",
      "------------------------------------\n",
      "1.047      | 0.9111     | 1.3474\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 1. é€»è¾‘å›å½’ ---\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_X_df)\n",
    "X_val_scaled = scaler.transform(val_X_df)\n",
    "\n",
    "# c_values = [round(x, 3) for x in np.arange(0.98, 1.1, 0.001)]\n",
    "c_values = [1.047] # 1.047æ•ˆæœä¸é”™\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"{'C Value':<10} | {'Accuracy':<10} | {'Perplexity':<10}\")\n",
    "print(\"-\" * 36)\n",
    "\n",
    "# --- å¾ªç¯è®­ç»ƒ ---\n",
    "for c in c_values:\n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    lr = LogisticRegression(C=c, random_state=42, max_iter=1000, solver='lbfgs')\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    lr.fit(X_train_scaled, train_y_df)\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    pred_class = lr.predict(X_val_scaled)\n",
    "    pred_proba = lr.predict_proba(X_val_scaled)[:, 1]\n",
    "    \n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    acc, perp = calculate_metrics(val_y_df, pred_class, pred_proba)\n",
    "    \n",
    "    # å­˜å…¥åˆ—è¡¨\n",
    "    results.append({\n",
    "        'C': c,\n",
    "        'Accuracy': acc,\n",
    "        'Perplexity': perp\n",
    "    })\n",
    "    \n",
    "    print(f\"{c:<10} | {acc:.4f}     | {perp:.4f}\")\n",
    "\n",
    "# # --- è½¬æ¢ä¸º DataFrame æ–¹ä¾¿ç»˜å›¾ ---\n",
    "# res_df = pd.DataFrame(results)\n",
    "\n",
    "# # --- ç»˜å›¾ (åŒè½´å›¾) ---\n",
    "# fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# # è®¾ç½® x è½´ä¸ºå¯¹æ•°åæ ‡ (å› ä¸º C å˜åŒ–èŒƒå›´å¤§)\n",
    "# ax1.set_xscale('log')\n",
    "# ax1.set_xlabel('C parameter (Inverse Regularization Strength)')\n",
    "# ax1.set_xticks(c_values)\n",
    "# ax1.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # æ˜¾ç¤ºå…·ä½“æ•°å­—è€Œé 10^x\n",
    "\n",
    "# # ç»˜åˆ¶å·¦è½´ï¼šå‡†ç¡®ç‡ (è¶Šé«˜è¶Šå¥½)\n",
    "# color = 'tab:blue'\n",
    "# ax1.set_ylabel('Accuracy (Higher is Better)', color=color, fontsize=12)\n",
    "# line1 = ax1.plot(res_df['C'], res_df['Accuracy'], marker='o', color=color, label='Accuracy', linewidth=2)\n",
    "# ax1.tick_params(axis='y', labelcolor=color)\n",
    "# ax1.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "\n",
    "# # ç»˜åˆ¶å³è½´ï¼šå›°æƒ‘åº¦ (è¶Šä½è¶Šå¥½)\n",
    "# ax2 = ax1.twinx()  # å…±äº« x è½´\n",
    "# color = 'tab:red'\n",
    "# ax2.set_ylabel('Perplexity (Lower is Better)', color=color, fontsize=12)\n",
    "# line2 = ax2.plot(res_df['C'], res_df['Perplexity'], marker='s', color=color, linestyle='--', label='Perplexity', linewidth=2)\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# # åˆå¹¶å›¾ä¾‹\n",
    "# lines = line1 + line2\n",
    "# labels = [l.get_label() for l in lines]\n",
    "# ax1.legend(lines, labels, loc='center right')\n",
    "\n",
    "# plt.title('Performance vs. Regularization (C)', fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# # --- æ‰¾å‡ºæœ€ä½³ C å€¼ ---\n",
    "# best_row = res_df.loc[res_df['Perplexity'].idxmin()]\n",
    "# print(f\"\\nğŸ† æœ€ä½³å‚æ•°: C = {best_row['C']}\")\n",
    "# print(f\"   å¯¹åº” Accuracy: {best_row['Accuracy']:.4f}\")\n",
    "# print(f\"   å¯¹åº” Perplexity: {best_row['Perplexity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75843227",
   "metadata": {},
   "source": [
    "C= 1.047ä¸ºæœ€å¥½ 1000æ¬¡å°±æ”¶æ•›äº†\n",
    "\n",
    "å¯¹åº” Accuracy: 0.9111\n",
    "å¯¹åº” Perplexity: 1.3474\n",
    "\n",
    "ä½†è¿™åªæ˜¯åœ¨random=42æ—¶çš„ç»“æœï¼Œè€Œä¸”åœ¨æµ‹è¯•é›†ä¸Šæœªå¿…å®Œå…¨å¯¹ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0a8a7afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- å¼€å§‹ Linear SVM å‚æ•°éå† (C) ---\n",
      "C Value    | Accuracy   | Perplexity | Time(s)   \n",
      "--------------------------------------------------\n",
      "1.59       | 0.9222     | 1.3678     | 0.11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"--- å¼€å§‹ Linear SVM å‚æ•°éå† (C) ---\")\n",
    "\n",
    "# 1. å‡†å¤‡æ•°æ® (SVM å¯¹æ ‡å‡†åŒ–æåº¦æ•æ„Ÿï¼Œå¿…é¡»ç¡®ä¿å·²æ ‡å‡†åŒ–)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_X_df)\n",
    "X_val_scaled = scaler.transform(val_X_df)\n",
    "\n",
    "# ç¡®ä¿æ ‡ç­¾æ ¼å¼æ­£ç¡®\n",
    "y_train_clean = train_y_df.values.ravel() if hasattr(train_y_df, 'values') else train_y_df\n",
    "y_val_clean = val_y_df.values.ravel() if hasattr(val_y_df, 'values') else val_y_df\n",
    "\n",
    "# 2. å®šä¹‰è¦æµ‹è¯•çš„ C å€¼ (å¯¹æ•°åˆ»åº¦)\n",
    "# C è¶Šå° = æ­£åˆ™åŒ–è¶Šå¼º (æ¨¡å‹è¶Šç®€å•/å¹³æ»‘)\n",
    "# C è¶Šå¤§ = æ­£åˆ™åŒ–è¶Šå¼± (è¯•å›¾æ‹Ÿåˆæ¯ä¸€ä¸ªç‚¹ï¼Œæ˜“è¿‡æ‹Ÿåˆ)\n",
    "# c_values = [round(x, 2) for x in np.arange(1.3, 1.9, 0.01)]\n",
    "c_values = [1.59]\n",
    "results = []\n",
    "\n",
    "print(f\"{'C Value':<10} | {'Accuracy':<10} | {'Perplexity':<10} | {'Time(s)':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 3. å¾ªç¯è®­ç»ƒ ---\n",
    "for c in c_values:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    # kernel='linear': çº¿æ€§æ ¸\n",
    "    # probability=True: å¿…é¡»å¼€å¯ï¼Œå¦åˆ™æ— æ³•è®¡ç®—å›°æƒ‘åº¦ (ä¼šå˜æ…¢)\n",
    "    svm = SVC(kernel='linear', C=c, probability=True, random_state=42)\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    svm.fit(X_train_scaled, y_train_clean)\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    pred_class = svm.predict(X_val_scaled)\n",
    "    pred_proba = svm.predict_proba(X_val_scaled)[:, 1]\n",
    "    \n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    acc, perp = calculate_metrics(y_val_clean, pred_class, pred_proba)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'C': c,\n",
    "        'Accuracy': acc,\n",
    "        'Perplexity': perp\n",
    "    })\n",
    "    \n",
    "    print(f\"{c:<10} | {acc:.4f}     | {perp:.4f}     | {elapsed:.2f}\")\n",
    "\n",
    "# # --- 4. æ•°æ®å¤„ç† ---\n",
    "# res_df = pd.DataFrame(results)\n",
    "\n",
    "# # --- 5. ç»˜åˆ¶åŒè½´å›¾ ---\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# # è®¾ç½® X è½´ä¸ºå¯¹æ•°åæ ‡\n",
    "# ax1.set_xscale('log')\n",
    "# ax1.set_xlabel('C Parameter (Regularization)', fontsize=12)\n",
    "# ax1.set_xticks(c_values)\n",
    "# ax1.get_xaxis().set_major_formatter(plt.ScalarFormatter()) \n",
    "# ax1.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "\n",
    "# # å·¦è½´ï¼šå‡†ç¡®ç‡ (è“è‰²)\n",
    "# color_acc = 'tab:blue'\n",
    "# ax1.set_ylabel('Accuracy (Higher is Better)', color=color_acc, fontsize=12)\n",
    "# line1 = ax1.plot(res_df['C'], res_df['Accuracy'], marker='o', color=color_acc, label='Accuracy', linewidth=2)\n",
    "# ax1.tick_params(axis='y', labelcolor=color_acc)\n",
    "\n",
    "# # å³è½´ï¼šå›°æƒ‘åº¦ (çº¢è‰²)\n",
    "# ax2 = ax1.twinx()\n",
    "# color_perp = 'tab:red'\n",
    "# ax2.set_ylabel('Perplexity (Lower is Better)', color=color_perp, fontsize=12)\n",
    "# line2 = ax2.plot(res_df['C'], res_df['Perplexity'], marker='s', linestyle='--', color=color_perp, label='Perplexity', linewidth=2)\n",
    "# ax2.tick_params(axis='y', labelcolor=color_perp)\n",
    "\n",
    "# # åˆå¹¶å›¾ä¾‹\n",
    "# lines = line1 + line2\n",
    "# labels = [l.get_label() for l in lines]\n",
    "# ax1.legend(lines, labels, loc='center right')\n",
    "\n",
    "# plt.title('Linear SVM: Performance vs. Regularization (C)', fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# # --- 6. è¾“å‡ºæœ€ä½³ç»“æœ ---\n",
    "# best_row = res_df.loc[res_df['Perplexity'].idxmin()]\n",
    "# print(f\"\\nğŸ† æœ€ä½³å‚æ•°: C = {best_row['C']}\")\n",
    "# print(f\"   å¯¹åº” Accuracy: {best_row['Accuracy']:.4f}\")\n",
    "# print(f\"   å¯¹åº” Perplexity: {best_row['Perplexity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a1933",
   "metadata": {},
   "source": [
    "\n",
    "ğŸ† æœ€ä½³å‚æ•°: C = 1.59\n",
    "   å¯¹åº” Accuracy: 0.9222\n",
    "   å¯¹åº” Perplexity: 1.3678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92f821e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # --- 1. å‡†å¤‡æ•°æ® ---\n",
    "# X_train = train_X_df\n",
    "# y_train = train_y_df.values.ravel() if hasattr(train_y_df, 'values') else train_y_df\n",
    "\n",
    "# print(\"--- å¼€å§‹æµ‹è¯• n_estimators (æ ‘çš„æ•°é‡) ---\")\n",
    "\n",
    "# # --- 2. å®šä¹‰å‚æ•°ç½‘æ ¼ ---\n",
    "# # âš ï¸ é‡è¦æç¤ºï¼šè¯·å°† max_depth å’Œ min_samples_leaf æ›¿æ¢ä¸ºä½ ä¸Šä¸€æ­¥çƒ­åŠ›å›¾ä¸­æ‰¾åˆ°çš„æœ€ä½³å€¼ï¼\n",
    "# # è¿™é‡Œæˆ‘æš‚æ—¶ç”¨ 12 å’Œ 8 ä½œä¸ºç¤ºä¾‹ (è¿™æ˜¯ä¸€ä¸ªé€šå¸¸ä¸é”™çš„ç»„åˆ)\n",
    "# fixed_depth = 12 \n",
    "# fixed_leaf = 8\n",
    "\n",
    "# param_grid = {\n",
    "#     # å˜é‡ï¼šæˆ‘ä»¬æƒ³æµ‹è¯•çš„æ ‘çš„æ•°é‡èŒƒå›´\n",
    "#     'n_estimators': list(range(200, 601, 10)),\n",
    "    \n",
    "#     # å›ºå®šå‚æ•°ï¼š\n",
    "#     'max_depth': [fixed_depth],\n",
    "#     'min_samples_leaf': [fixed_leaf],\n",
    "#     'max_features': ['sqrt']\n",
    "# }\n",
    "\n",
    "# # --- 3. åˆå§‹åŒ–å¹¶è®­ç»ƒ ---\n",
    "# scoring_metrics = {\n",
    "#     'Accuracy': 'accuracy', \n",
    "#     'LogLoss': 'neg_log_loss'\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring=scoring_metrics,\n",
    "#     refit='LogLoss',\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(\"è®­ç»ƒå®Œæˆï¼\")\n",
    "\n",
    "# # --- 4. æå–ç»“æœ ---\n",
    "# results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# plot_df = results_df[[\n",
    "#     'param_n_estimators', \n",
    "#     'mean_test_Accuracy', \n",
    "#     'mean_test_LogLoss'\n",
    "# ]].copy()\n",
    "\n",
    "# # è®¡ç®—å›°æƒ‘åº¦\n",
    "# plot_df['LogLoss'] = -plot_df['mean_test_LogLoss']\n",
    "# plot_df['Perplexity'] = np.exp(plot_df['LogLoss'])\n",
    "# plot_df['n_estimators'] = plot_df['param_n_estimators'].astype(int)\n",
    "\n",
    "# # --- 5. ç»˜åˆ¶åŒè½´æŠ˜çº¿å›¾ (Dual Axis Line Plot) ---\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# # è®¾ç½® X è½´\n",
    "# ax1.set_xlabel('Number of Trees (n_estimators)', fontsize=12)\n",
    "# ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# # --- å·¦è½´ï¼šå‡†ç¡®ç‡ (è“è‰²) ---\n",
    "# color_acc = 'tab:blue'\n",
    "# ax1.set_ylabel('Accuracy (Higher is Better)', color=color_acc, fontsize=12)\n",
    "# line1 = ax1.plot(plot_df['n_estimators'], plot_df['mean_test_Accuracy'], \n",
    "#                  marker='o', color=color_acc, label='Accuracy', linewidth=2)\n",
    "# ax1.tick_params(axis='y', labelcolor=color_acc)\n",
    "\n",
    "# # --- å³è½´ï¼šå›°æƒ‘åº¦ (çº¢è‰²) ---\n",
    "# ax2 = ax1.twinx()  # å…±äº« X è½´\n",
    "# color_perp = 'tab:red'\n",
    "# ax2.set_ylabel('Perplexity (Lower is Better)', color=color_perp, fontsize=12)\n",
    "# line2 = ax2.plot(plot_df['n_estimators'], plot_df['Perplexity'], \n",
    "#                  marker='s', linestyle='--', color=color_perp, label='Perplexity', linewidth=2)\n",
    "# ax2.tick_params(axis='y', labelcolor=color_perp)\n",
    "\n",
    "# # åˆå¹¶å›¾ä¾‹\n",
    "# lines = line1 + line2\n",
    "# labels = [l.get_label() for l in lines]\n",
    "# ax1.legend(lines, labels, loc='center right')\n",
    "\n",
    "# plt.title(f'Effect of n_estimators (fixed depth={fixed_depth}, leaf={fixed_leaf})', fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# # --- è¾“å‡ºæœ€ä½³ç»“æœ ---\n",
    "# best_idx = grid_search.best_index_\n",
    "# print(f\"\\nğŸ† æœ€ä½³æ ‘æ•°é‡:\")\n",
    "# print(f\"   n_estimators: {results_df.loc[best_idx, 'param_n_estimators']}\")\n",
    "# print(f\"   å¯¹åº” Accuracy: {results_df.loc[best_idx, 'mean_test_Accuracy']:.4f}\")\n",
    "# print(f\"   å¯¹åº” Perplexity: {np.exp(-results_df.loc[best_idx, 'mean_test_LogLoss']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6dfce",
   "metadata": {},
   "source": [
    "ğŸ† ç»¼åˆæœ€ä½³å‚æ•° (åŸºäº LogLoss):\n",
    "\n",
    "   Max Depth: 5\n",
    "\n",
    "   Min Samples Leaf: 4\n",
    "\n",
    "   å¯¹åº” Accuracy: 0.8750\n",
    "   å¯¹åº” Perplexity: 1.3955\n",
    "\n",
    "   æ”¹å˜n_estimatorsè¿˜ä¼šæœ‰ç»“æœå˜åŒ–ï¼Œä½†æ˜¯å½±å“ä¸å¤§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3e9a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(\"--- å¼€å§‹ XGBoost å‚æ•°ç½‘æ ¼æœç´¢ (Accuracy & LogLoss) ---\")\n",
    "\n",
    "# # 1. å‡†å¤‡æ•°æ®\n",
    "# X_train = train_X_df\n",
    "# y_train = train_y_df.values.ravel() if hasattr(train_y_df, 'values') else train_y_df\n",
    "\n",
    "# # 2. å®šä¹‰å‚æ•°ç½‘æ ¼\n",
    "# # æ³¨æ„ï¼šXGBoost çš„æ·±åº¦é€šå¸¸æ¯”éšæœºæ£®æ—è¦æµ…å¾ˆå¤š (3-10æ˜¯å¸¸è§èŒƒå›´)\n",
    "# param_grid = {\n",
    "#     # å›ºå®šå‚æ•° (ä¸ºäº†æ§åˆ¶è®¡ç®—æ—¶é—´)\n",
    "#     'n_estimators': [200], \n",
    "#     'learning_rate': [0.05], \n",
    "    \n",
    "#     # å˜é‡å‚æ•°ï¼šæˆ‘ä»¬éœ€è¦è°ƒèŠ‚è¿™ä¸¤ä¸ªæ¥å¹³è¡¡ å‡†ç¡®ç‡ vs å›°æƒ‘åº¦\n",
    "#     'max_depth': [2, 4, 6, 8, 10], \n",
    "#     'min_child_weight': [1, 3, 5, 7, 9, 11] # ç±»ä¼¼äº min_samples_leafï¼Œè¶Šå¤§è¶Šä¿å®ˆ\n",
    "# }\n",
    "\n",
    "# # 3. åˆå§‹åŒ–æ¨¡å‹ä¸æœç´¢\n",
    "# # use_label_encoder=False æ¶ˆé™¤è­¦å‘Š\n",
    "# # eval_metric='logloss' ä¼˜åŒ–å›°æƒ‘åº¦\n",
    "# xgb = XGBClassifier(\n",
    "#     use_label_encoder=False, \n",
    "#     eval_metric='logloss', \n",
    "#     random_state=42, \n",
    "#     n_jobs=-1,\n",
    "#     verbosity=0 # é™é»˜æ¨¡å¼\n",
    "# )\n",
    "\n",
    "# scoring_metrics = {\n",
    "#     'Accuracy': 'accuracy', \n",
    "#     'LogLoss': 'neg_log_loss'\n",
    "# }\n",
    "\n",
    "# grid_search_xgb = GridSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring=scoring_metrics,\n",
    "#     refit='LogLoss',\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # 4. è®­ç»ƒ\n",
    "# grid_search_xgb.fit(X_train, y_train)\n",
    "# print(\"è®­ç»ƒå®Œæˆï¼\")\n",
    "\n",
    "# # --- 5. æå–ç»“æœå¹¶ç»˜å›¾ ---\n",
    "# results_df = pd.DataFrame(grid_search_xgb.cv_results_)\n",
    "\n",
    "# # æå–æ•°æ®\n",
    "# plot_df = results_df[[\n",
    "#     'param_max_depth', \n",
    "#     'param_min_child_weight', \n",
    "#     'mean_test_Accuracy', \n",
    "#     'mean_test_LogLoss'\n",
    "# ]].copy()\n",
    "\n",
    "# # è½¬æ¢æŒ‡æ ‡\n",
    "# plot_df['LogLoss'] = -plot_df['mean_test_LogLoss']\n",
    "# plot_df['Perplexity'] = np.exp(plot_df['LogLoss'])\n",
    "# plot_df['max_depth'] = plot_df['param_max_depth'].astype(int)\n",
    "# plot_df['min_child_weight'] = plot_df['param_min_child_weight'].astype(int)\n",
    "\n",
    "# # å‡†å¤‡ç»˜å›¾é€è§†è¡¨\n",
    "# pivot_acc = plot_df.pivot(index='max_depth', columns='min_child_weight', values='mean_test_Accuracy')\n",
    "# pivot_perp = plot_df.pivot(index='max_depth', columns='min_child_weight', values='Perplexity')\n",
    "\n",
    "# # ç»˜åˆ¶åŒçƒ­åŠ›å›¾\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# # å›¾ 1: å‡†ç¡®ç‡ (Accuracy)\n",
    "# sns.heatmap(pivot_acc, ax=axes[0], annot=True, fmt=\".3f\", cmap=\"viridis\", cbar_kws={'label': 'Accuracy'})\n",
    "# axes[0].set_title('XGBoost: Accuracy (Higher is Better)', fontsize=15)\n",
    "# axes[0].set_xlabel('Min Child Weight (Conservation)')\n",
    "# axes[0].set_ylabel('Max Depth (Complexity)')\n",
    "\n",
    "# # å›¾ 2: å›°æƒ‘åº¦ (Perplexity)\n",
    "# sns.heatmap(pivot_perp, ax=axes[1], annot=True, fmt=\".3f\", cmap=\"RdYlGn_r\", cbar_kws={'label': 'Perplexity'})\n",
    "# axes[1].set_title('XGBoost: Perplexity (Lower is Better)', fontsize=15)\n",
    "# axes[1].set_xlabel('Min Child Weight (Conservation)')\n",
    "# axes[1].set_ylabel('Max Depth (Complexity)')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # --- è¾“å‡ºæœ€ä½³ç»“æœ ---\n",
    "# best_idx = grid_search_xgb.best_index_\n",
    "# print(f\"\\nğŸ† XGBoost æœ€ä½³å‚æ•° (åŸºäº LogLoss):\")\n",
    "# print(f\"   Max Depth: {results_df.loc[best_idx, 'param_max_depth']}\")\n",
    "# print(f\"   Min Child Weight: {results_df.loc[best_idx, 'param_min_child_weight']}\")\n",
    "# print(f\"   å¯¹åº” Accuracy: {results_df.loc[best_idx, 'mean_test_Accuracy']:.4f}\")\n",
    "# print(f\"   å¯¹åº” Perplexity: {np.exp(-results_df.loc[best_idx, 'mean_test_LogLoss']):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "In2ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
